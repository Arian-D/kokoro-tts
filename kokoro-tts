#!/usr/bin/env python3

import soundfile as sf
import sounddevice as sd
from kokoro_onnx import Kokoro
import os
import sys
import itertools
import threading
import time
import signal
from ebooklib import epub
from bs4 import BeautifulSoup
import warnings
from threading import Event
import difflib
import xml.etree.ElementTree as ET

warnings.filterwarnings("ignore", category=UserWarning, module='ebooklib')
warnings.filterwarnings("ignore", category=FutureWarning, module='ebooklib')

# Global flag to stop the spinner and audio
stop_spinner = False
stop_audio = False

def spinning_wheel(message="Processing...", progress=None):
    """Display a spinning wheel with a message."""
    spinner = itertools.cycle(['⠋', '⠙', '⠹', '⠸', '⠼', '⠴', '⠦', '⠧', '⠇', '⠏'])
    while not stop_spinner:
        spin = next(spinner)
        if progress is not None:
            sys.stdout.write(f"\r{message} {progress} {spin}")
        else:
            sys.stdout.write(f"\r{message} {spin}")
        sys.stdout.flush()
        time.sleep(0.1)
    # Clear the spinner line when done
    sys.stdout.write('\r' + ' ' * (len(message) + 50) + '\r')
    sys.stdout.flush()

def list_available_voices(kokoro):
    voices = list(kokoro.get_voices())
    print("Available voices:")
    for idx, voice in enumerate(voices):
        print(f"{idx + 1}. {voice}")
    return voices

def extract_text_from_epub(epub_file):
    book = epub.read_epub(epub_file)
    full_text = ""
    for item in book.get_items():
        # Check if the item is a document based on mime type (e.g., text/html, application/xhtml+xml)
        if item.get_type() == 9:  # 9 corresponds to DOCUMENT in ebooklib
            soup = BeautifulSoup(item.get_body_content(), "html.parser")  # Use get_body_content() here
            full_text += soup.get_text()
    return full_text

def chunk_text(text, chunk_size=2000):
    """Split text into chunks at sentence boundaries."""
    sentences = text.replace('\n', ' ').split('.')
    chunks = []
    current_chunk = []
    current_size = 0
    
    for sentence in sentences:
        if not sentence.strip():
            continue  # Skip empty sentences
        
        sentence = sentence.strip() + '.'
        sentence_size = len(sentence)
        
        # Start new chunk if current one would be too large
        if current_size + sentence_size > chunk_size and current_chunk:
            chunks.append(' '.join(current_chunk))
            current_chunk = []
            current_size = 0
        
        current_chunk.append(sentence)
        current_size += sentence_size
    
    if current_chunk:
        chunks.append(' '.join(current_chunk))
    
    return chunks

def validate_language(lang, kokoro):
    """Validate if the language is supported."""
    try:
        supported_languages = set(kokoro.get_languages())  # Get supported languages from Kokoro
        if lang not in supported_languages:
            supported_langs = ', '.join(sorted(supported_languages))
            raise ValueError(f"Unsupported language: {lang}\nSupported languages are: {supported_langs}")
        return lang
    except Exception as e:
        print(f"Error getting supported languages: {e}")
        sys.exit(1)

def print_usage():
    print("""
Usage: kokoro-tts <input_text_file> [<output_audio_file>] [options]

Commands:
    -h, --help         Show this help message
    --help-languages   List all supported languages
    --help-voices      List all available voices
    --merge-chunks     Merge existing chunks in split-output directory into chapter files

Options:
    --stream            Stream audio instead of saving to file
    --speed <float>     Set speech speed (default: 1.0)
    --lang <str>        Set language (default: en-us)
    --voice <str>       Set voice (default: interactive selection)
    --split-output <dir> Save each chunk as separate file in directory
    --format <str>      Audio format: wav or mp3 (default: wav)
    --debug             Show detailed debug information

Input formats:
    .txt               Text file input
    .epub              EPUB book input (will process chapters)

Examples:
    kokoro-tts input.txt output.wav --speed 1.2 --lang en-us --voice af_sarah
    kokoro-tts input.epub --split-output ./chunks/ --format mp3
    kokoro-tts input.txt --stream --speed 0.8
    kokoro-tts --merge-chunks --split-output ./chunks/ --format wav
    kokoro-tts --help-voices
    kokoro-tts --help-languages
    kokoro-tts input.epub --split-output ./chunks/ --debug
    """)

def print_supported_languages():
    """Print all supported languages from Kokoro."""
    try:
        kokoro = Kokoro("kokoro-v0_19.onnx", "voices.json")
        languages = sorted(kokoro.get_languages())
        print("\nSupported languages:")
        for lang in languages:
            print(f"    {lang}")
        print()
    except Exception as e:
        print(f"Error loading model to get supported languages: {e}")
        sys.exit(1)

def print_supported_voices():
    """Print all supported voices from Kokoro."""
    try:
        kokoro = Kokoro("kokoro-v0_19.onnx", "voices.json")
        voices = sorted(kokoro.get_voices())
        print("\nSupported voices:")
        for idx, voice in enumerate(voices):
            print(f"    {idx + 1}. {voice}")
        print()
    except Exception as e:
        print(f"Error loading model to get supported voices: {e}")
        sys.exit(1)

def validate_voice(voice, kokoro):
    """Validate if the voice is supported."""
    try:
        supported_voices = set(kokoro.get_voices())
        if voice not in supported_voices:
            supported_voices = ', '.join(sorted(supported_voices))
            raise ValueError(f"Unsupported voice: {voice}\nSupported voices are: {supported_voices}")
        return voice
    except Exception as e:
        print(f"Error getting supported voices: {e}")
        sys.exit(1)

def extract_chapters_from_epub(epub_file, debug=False):
    """Extract chapters from epub file with their titles using NCX when available."""
    book = epub.read_epub(epub_file)
    chapters = []
    chapter_titles = {}
    
    # First try to get chapter titles from NCX
    ncx_found = False
    
    if debug:
        print("\nSearching for NCX file...")
        for item in book.get_items():
            print(f"Found item: {item.file_name} (type: {item.get_type()})")
    
    # Try to find NCX file
    for item in book.get_items():
        if item.get_type() == 3 or (item.file_name and item.file_name.lower().endswith('.ncx')):
            try:
                if debug:
                    print(f"\nFound NCX file: {item.file_name}")
                    print("\nNCX Content Preview:")
                    print(item.content[:500])
                
                ncx_found = True
                
                # Define XML namespaces
                ns = {'ncx': 'http://www.daisy.org/z3986/2005/ncx/'}
                
                # Parse NCX content
                root = ET.fromstring(item.content)
                
                # Find all navPoints
                nav_points = root.findall('.//ncx:navPoint', ns)
                if not nav_points:
                    # Try without namespace if not found
                    nav_points = root.findall('.//navPoint')
                
                print(f"\nFound {len(nav_points)} nav points")
                
                for nav in nav_points:
                    try:
                        play_order = int(nav.get('playOrder', 0))
                        
                        # Try with and without namespace
                        nav_label = nav.find('.//ncx:navLabel/ncx:text', ns)
                        if nav_label is None:
                            nav_label = nav.find('.//navLabel/text')
                        
                        if nav_label is not None:
                            title = nav_label.text.strip()
                        else:
                            continue
                        
                        # Try with and without namespace
                        content = nav.find('.//ncx:content', ns)
                        if content is None:
                            content = nav.find('.//content')
                        
                        if content is not None:
                            content_src = content.get('src', '')
                        else:
                            continue
                        
                        # Clean up the content source path
                        content_src = content_src.lower()
                        base_name = os.path.basename(content_src)
                        
                        print(f"Found chapter: {play_order}. {title} -> {base_name}")
                        
                        chapter_titles[base_name] = {
                            'order': play_order,
                            'title': title
                        }
                    except Exception as e:
                        print(f"Warning: Error processing nav point: {e}")
                        continue
                
                print(f"\nProcessed {len(chapter_titles)} chapter titles")
                if chapter_titles:
                    break
            except Exception as e:
                print(f"Warning: Error parsing NCX file: {e}")
                import traceback
                traceback.print_exc()
                continue
    
    if not ncx_found:
        print("Warning: No NCX file found in EPUB!")
    elif not chapter_titles:
        print("Warning: No chapters found in NCX file!")
    
    # Now process the actual content
    print("\nProcessing content files:")
    for item in book.get_items():
        if item.get_type() == 9:  # 9 is for DOCUMENT/content files
            try:
                # Clean up the file name for matching
                file_name = os.path.basename(item.file_name.lower())
                
                print(f"\nProcessing file: {file_name}")
                
                content = item.get_content().decode('utf-8')
                soup = BeautifulSoup(content, "html.parser")
                text_content = soup.get_text().strip()
                
                if text_content and file_name in chapter_titles:  # Only add if there's content and matching title
                    title = chapter_titles[file_name]['title']
                    order = chapter_titles[file_name]['order']
                    
                    # Skip if this is not a main chapter (like copyright page)
                    if title.lower() in ['copy', 'copyright']:
                        print(f"Skipping: {title}")
                        continue
                    
                    chapters.append({
                        'title': title,
                        'content': text_content,
                        'order': order
                    })
                    print(f"Added chapter: {title}")
                else:
                    if not text_content:
                        print(f"Skipping: {file_name} (no content)")
                    elif file_name not in chapter_titles:
                        print(f"Skipping: {file_name} (no matching title)")
            except Exception as e:
                print(f"Warning: Error processing content file: {e}")
                import traceback
                traceback.print_exc()
                continue
    
    # Sort chapters by order
    chapters.sort(key=lambda x: x['order'])
    
    # Debug info
    if not chapters:
        print("\nWarning: No chapters were extracted!")
        if chapter_titles:
            print("Available NCX entries:")
            for src, info in chapter_titles.items():
                print(f"  {info['order']}. {info['title']} ({src})")
            print("\nFound HTML files:")
            for item in book.get_items():
                if item.get_type() == 9:
                    print(f"  {os.path.basename(item.file_name.lower())}")
    else:
        print(f"\nSuccessfully extracted {len(chapters)} chapters:")
        for chapter in chapters:
            print(f"  {chapter['order']}. {chapter['title']}")
    
    return chapters

def process_chunk_sequential(chunk, kokoro, voice, speed, lang):
    """Process a single chunk of text sequentially."""
    try:
        samples, sample_rate = kokoro.create(chunk, voice=voice, speed=speed, lang=lang)
        return samples, sample_rate
    except Exception as e:
        print(f"\nError processing chunk: {e}")
        return None, None

def convert_text_to_audio(input_file, output_file=None, voice=None, speed=1.0, lang="en-us", 
                         stream=False, split_output=None, format="wav", debug=False):
    global stop_spinner
    # Load Kokoro model
    try:
        kokoro = Kokoro("kokoro-v0_19.onnx", "voices.json")
        # Validate language after loading model
        lang = validate_language(lang, kokoro)
        
        # Handle voice selection
        if voice:
            voice = validate_voice(voice, kokoro)
        else:
            # Interactive voice selection
            voices = list_available_voices(kokoro)
            try:
                voice_choice = int(input("Choose a voice by number: ")) - 1
                if voice_choice < 0 or voice_choice >= len(voices):
                    raise ValueError("Invalid choice")
                voice = voices[voice_choice]
            except (ValueError, IndexError):
                print("Invalid choice. Using default voice.")
                voice = "af_sarah"  # default voice
    except ValueError as e:
        print(f"Error: {e}")
        sys.exit(1)
    except Exception as e:
        print(f"Error loading Kokoro model: {e}")
        sys.exit(1)
    
    # Read the input file (handle .txt or .epub)
    if input_file.endswith('.epub'):
        chapters = extract_chapters_from_epub(input_file, debug)
        if not chapters:
            print("No chapters found in EPUB file.")
            sys.exit(1)
            
        # Print summary before starting
        total_words = sum(len(chapter['content'].split()) for chapter in chapters)
        print("\nBook Summary:")
        print(f"Total Chapters: {len(chapters)}")
        print(f"Total Words: {total_words:,}")
        print(f"Total Duration: {total_words / 150:.1f} minutes")
        
        if debug:
            print("\nDetailed Chapter List:")
            for chapter in chapters:
                word_count = len(chapter['content'].split())
                print(f"  • {chapter['title']}")
                print(f"    Words: {word_count:,}")
                print(f"    Duration: {word_count / 150:.1f} minutes")
        
        print("\nPress Enter to start processing, or Ctrl+C to cancel...")
        input()
        
        if split_output:
            os.makedirs(split_output, exist_ok=True)
            
            # First create all chapter directories and info files
            print("\nCreating chapter directories and info files...")
            for chapter_num, chapter in enumerate(chapters, 1):
                chapter_dir = os.path.join(split_output, f"chapter_{chapter_num:03d}")
                os.makedirs(chapter_dir, exist_ok=True)
                
                # Write chapter info with more details
                info_file = os.path.join(chapter_dir, "info.txt")
                with open(info_file, "w", encoding="utf-8") as f:
                    f.write(f"Title: {chapter['title']}\n")
                    f.write(f"Order: {chapter['order']}\n")
                    f.write(f"Words: {len(chapter['content'].split())}\n")
                    f.write(f"Estimated Duration: {len(chapter['content'].split()) / 150:.1f} minutes\n")
            
            print("Created chapter directories and info files")
            
            # Continue with existing processing code...
    else:
        with open(input_file, 'r', encoding='utf-8') as file:
            text = file.read()
        # Treat single text file as one chapter
        chapters = [{'title': 'Chapter 1', 'content': text}]

    if stream:
        import asyncio
        # Stream each chapter
        for chapter in chapters:
            print(f"\nStreaming: {chapter['title']}")
            asyncio.run(stream_audio(kokoro, chapter['content'], voice, speed, lang))
    else:
        if split_output:
            os.makedirs(split_output, exist_ok=True)
            
            for chapter_num, chapter in enumerate(chapters, 1):
                chapter_dir = os.path.join(split_output, f"chapter_{chapter_num:03d}")
                
                # Skip if chapter is already fully processed
                if os.path.exists(chapter_dir):
                    info_file = os.path.join(chapter_dir, "info.txt")
                    if os.path.exists(info_file):
                        chunks = chunk_text(chapter['content'], chunk_size=2000)
                        total_chunks = len(chunks)
                        existing_chunks = len([f for f in os.listdir(chapter_dir) 
                                            if f.startswith("chunk_") and f.endswith(f".{format}")])
                        
                        if existing_chunks == total_chunks:
                            print(f"\nSkipping {chapter['title']}: Already completed ({existing_chunks} chunks)")
                            continue
                        else:
                            print(f"\nResuming {chapter['title']}: Found {existing_chunks}/{total_chunks} chunks")

                print(f"\nProcessing: {chapter['title']}")
                os.makedirs(chapter_dir, exist_ok=True)
                
                # Write chapter info if not exists
                info_file = os.path.join(chapter_dir, "info.txt")
                if not os.path.exists(info_file):
                    with open(info_file, "w", encoding="utf-8") as f:
                        f.write(f"Title: {chapter['title']}\n")
                
                chunks = chunk_text(chapter['content'], chunk_size=2000)
                total_chunks = len(chunks)
                processed_chunks = len([f for f in os.listdir(chapter_dir) 
                                     if f.startswith("chunk_") and f.endswith(f".{format}")])
                
                for chunk_num, chunk in enumerate(chunks, 1):
                    if stop_audio:  # Check for interruption
                        break
                    
                    # Skip if chunk file already exists (regardless of position)
                    chunk_file = os.path.join(chapter_dir, f"chunk_{chunk_num:03d}.{format}")
                    if os.path.exists(chunk_file):
                        continue  # Don't increment processed_chunks here since we counted them above
                    
                    # Create progress bar
                    filled = "■" * processed_chunks
                    remaining = "□" * (total_chunks - processed_chunks)
                    progress_bar = f"[{filled}{remaining}] ({processed_chunks}/{total_chunks})"
                    
                    stop_spinner = False
                    spinner_thread = threading.Thread(
                        target=spinning_wheel,
                        args=(f"Processing {chapter['title']}", progress_bar)
                    )
                    spinner_thread.start()
                    
                    try:
                        samples, sample_rate = process_chunk_sequential(chunk, kokoro, voice, speed, lang)
                        if samples is not None:
                            sf.write(chunk_file, samples, sample_rate)
                            processed_chunks += 1
                    except Exception as e:
                        print(f"\nError processing chunk {chunk_num}: {e}")
                    
                    stop_spinner = True
                    spinner_thread.join()
                    
                    if stop_audio:  # Check for interruption
                        break
                
                print(f"\nCompleted {chapter['title']}: {processed_chunks}/{total_chunks} chunks processed")
                
                if stop_audio:  # Check for interruption
                    break
            
            print(f"\nCreated audio files for {len(chapters)} chapters in {split_output}/")
        else:
            # Combine all chapters into one file
            all_samples = []
            sample_rate = None
            
            for chapter_num, chapter in enumerate(chapters, 1):
                print(f"\nProcessing: {chapter['title']}")
                chunks = chunk_text(chapter['content'], chunk_size=2000)
                processed_chunks = 0
                total_chunks = len(chunks)
                
                for chunk_num, chunk in enumerate(chunks, 1):
                    if stop_audio:  # Check for interruption
                        break
                    
                    stop_spinner = False
                    spinner_thread = threading.Thread(
                        target=spinning_wheel,
                        args=(f"Processing chunk {chunk_num}/{total_chunks}",)
                    )
                    spinner_thread.start()
                    
                    try:
                        samples, sr = process_chunk_sequential(chunk, kokoro, voice, speed, lang)
                        if samples is not None:
                            if sample_rate is None:
                                sample_rate = sr
                            all_samples.extend(samples)
                            processed_chunks += 1
                    except Exception as e:
                        print(f"\nError processing chunk {chunk_num}: {e}")
                    
                    stop_spinner = True
                    spinner_thread.join()
                
                print(f"\nCompleted {chapter['title']}: {processed_chunks}/{total_chunks} chunks processed")
            
            if all_samples:
                print("\nSaving complete audio file...")
                if not output_file:
                    output_file = f"{os.path.splitext(input_file)[0]}.{format}"
                sf.write(output_file, all_samples, sample_rate)
                print(f"Created {output_file}")

async def stream_audio(kokoro, text, voice, speed, lang):
    global stop_spinner, stop_audio
    stop_spinner = False
    stop_audio = False
    
    print("Starting audio stream...")
    chunks = chunk_text(text)
    
    for i, chunk in enumerate(chunks, 1):
        if stop_audio:
            break
        # Update progress percentage
        progress = int((i / len(chunks)) * 100)
        spinner_thread = threading.Thread(
            target=spinning_wheel, 
            args=(f"Streaming chunk {i}/{len(chunks)}",)
        )
        spinner_thread.start()
        
        async for samples, sample_rate in kokoro.create_stream(
            chunk, voice=voice, speed=speed, lang=lang
        ):
            if stop_audio:
                break
            sd.play(samples, sample_rate)
            sd.wait()
        
        stop_spinner = True
        spinner_thread.join()
        stop_spinner = False
    
    print("\nStreaming completed.")

def handle_ctrl_c(signum, frame):
    global stop_spinner, stop_audio
    print("\nCtrl+C detected, stopping...")
    stop_spinner = True
    stop_audio = True
    sys.exit(0)

# Register the signal handler for SIGINT (Ctrl+C)
signal.signal(signal.SIGINT, handle_ctrl_c)

def merge_chunks_to_chapters(split_output_dir, format="wav"):
    """Merge audio chunks into complete chapter files."""
    global stop_spinner

    if not os.path.exists(split_output_dir):
        print(f"Error: Directory {split_output_dir} does not exist.")
        return

    # Find all chapter directories
    chapter_dirs = sorted([d for d in os.listdir(split_output_dir) 
                          if d.startswith("chapter_") and os.path.isdir(os.path.join(split_output_dir, d))])
    
    if not chapter_dirs:
        print(f"No chapter directories found in {split_output_dir}")
        return

    for chapter_dir in chapter_dirs:
        chapter_path = os.path.join(split_output_dir, chapter_dir)
        chunk_files = sorted([f for f in os.listdir(chapter_path) 
                            if f.startswith("chunk_") and f.endswith(f".{format}")])
        
        if not chunk_files:
            print(f"No chunks found in {chapter_dir}")
            continue

        # Read chapter title from info.txt if available
        chapter_title = chapter_dir
        info_file = os.path.join(chapter_path, "info.txt")
        if os.path.exists(info_file):
            with open(info_file, 'r', encoding='utf-8') as f:
                for line in f:
                    if line.startswith("Title:"):
                        chapter_title = line.replace("Title:", "").strip()
                        break

        print(f"\nMerging chunks for {chapter_title}")
        
        # Initialize variables for merging
        all_samples = []
        sample_rate = None
        total_duration = 0
        
        # Create progress spinner
        total_chunks = len(chunk_files)
        processed_chunks = 0
        
        for chunk_file in chunk_files:
            chunk_path = os.path.join(chapter_path, chunk_file)
            
            # Display progress
            print(f"\rProcessing chunk {processed_chunks + 1}/{total_chunks}", end="")
            
            try:
                # Read audio data
                data, sr = sf.read(chunk_path)
                
                # Verify the audio data
                if len(data) == 0:
                    print(f"\nWarning: Empty audio data in {chunk_file}")
                    continue
                
                # Initialize sample rate or verify it matches
                if sample_rate is None:
                    sample_rate = sr
                elif sr != sample_rate:
                    print(f"\nWarning: Sample rate mismatch in {chunk_file}")
                    continue
                
                # Add chunk duration to total
                chunk_duration = len(data) / sr
                total_duration += chunk_duration
                
                # Append the audio data
                all_samples.extend(data)
                processed_chunks += 1
                
            except Exception as e:
                print(f"\nError processing {chunk_file}: {e}")
        
        print()  # New line after progress
        
        if all_samples:
            # Create merged file name
            merged_file = os.path.join(split_output_dir, f"{chapter_dir}.{format}")
            print(f"Saving merged chapter to {merged_file}")
            print(f"Total duration: {total_duration:.2f} seconds")
            
            try:
                # Ensure all_samples is a numpy array
                import numpy as np
                all_samples = np.array(all_samples)
                
                # Save merged audio
                sf.write(merged_file, all_samples, sample_rate)
                print(f"Successfully merged {processed_chunks}/{total_chunks} chunks")
                
                # Verify the output file
                if os.path.exists(merged_file):
                    output_data, output_sr = sf.read(merged_file)
                    output_duration = len(output_data) / output_sr
                    print(f"Verified output file: {output_duration:.2f} seconds")
                else:
                    print("Warning: Output file was not created")
                
            except Exception as e:
                print(f"Error saving merged file: {e}")
        else:
            print("No valid audio data to merge")

def get_valid_options():
    """Return a set of valid command line options"""
    return {
        '-h', '--help',
        '--help-languages',
        '--help-voices',
        '--merge-chunks',
        '--stream',
        '--speed',
        '--lang',
        '--voice',
        '--split-output',
        '--format',
        '--debug'  # Add debug option
    }

if __name__ == "__main__":
    # Validate command line options first
    valid_options = get_valid_options()
    unknown_options = []
    
    # Check for unknown options
    i = 1
    while i < len(sys.argv):
        arg = sys.argv[i]
        if arg.startswith('--') or arg.startswith('-'):
            # Check if it's a valid option
            if arg not in valid_options:
                unknown_options.append(arg)
            # Skip the next argument if it's a value for an option that takes parameters
            elif arg in {'--speed', '--lang', '--voice', '--split-output', '--format'}:
                i += 1
        i += 1
    
    # If unknown options were found, show error and help
    if unknown_options:
        print("Error: Unknown option(s):", ", ".join(unknown_options))
        print("\nDid you mean one of these?")
        for unknown in unknown_options:
            # Find similar valid options using string similarity
            similar = difflib.get_close_matches(unknown, valid_options, n=3, cutoff=0.4)
            if similar:
                print(f"  {unknown} -> {', '.join(similar)}")
        print("\n")  # Add extra newline for spacing
        print_usage()  # Show the full help text
        sys.exit(1)
    
    # Handle help commands first
    if len(sys.argv) == 2:
        if sys.argv[1] in ['-h', '--help']:
            print_usage()
            sys.exit(0)
        elif sys.argv[1] == '--help-languages':
            print_supported_languages()
            sys.exit(0)
        elif sys.argv[1] == '--help-voices':
            print_supported_voices()
            sys.exit(0)
    
    # Parse arguments
    input_file = None
    if len(sys.argv) > 1 and not sys.argv[1].startswith('--'):
        input_file = sys.argv[1]
        output_file = sys.argv[2] if len(sys.argv) > 2 and not sys.argv[2].startswith('--') else None
    else:
        output_file = None

    stream = '--stream' in sys.argv
    speed = 1.0  # default speed
    lang = "en-us"  # default language
    voice = None  # default to interactive selection
    split_output = None
    format = "wav"  # default format
    merge_chunks = '--merge-chunks' in sys.argv
    
    # Parse optional arguments
    for i, arg in enumerate(sys.argv):
        if arg == '--speed' and i + 1 < len(sys.argv):
            try:
                speed = float(sys.argv[i + 1])
            except ValueError:
                print("Error: Speed must be a number")
                sys.exit(1)
        elif arg == '--lang' and i + 1 < len(sys.argv):
            lang = sys.argv[i + 1]
        elif arg == '--voice' and i + 1 < len(sys.argv):
            voice = sys.argv[i + 1]
        elif arg == '--split-output' and i + 1 < len(sys.argv):
            split_output = sys.argv[i + 1]
        elif arg == '--format' and i + 1 < len(sys.argv):
            format = sys.argv[i + 1].lower()
            if format not in ['wav', 'mp3']:
                print("Error: Format must be either 'wav' or 'mp3'")
                sys.exit(1)
    
    # Handle merge chunks operation
    if merge_chunks:
        if not split_output:
            print("Error: --split-output directory must be specified when using --merge-chunks")
            sys.exit(1)
        merge_chunks_to_chapters(split_output, format)
        sys.exit(0)
    
    # Normal processing mode
    if not input_file:
        print("Error: Input file required for text-to-speech conversion")
        print_usage()
        sys.exit(1)

    # Ensure the input file exists
    if not os.path.isfile(input_file):
        print(f"Error: The file {input_file} does not exist.")
        sys.exit(1)
    
    # Ensure the output file has a proper extension if specified
    if output_file and not output_file.endswith(('.' + format)):
        print(f"Error: Output file must have .{format} extension.")
        sys.exit(1)
    
    # Add debug flag
    debug = '--debug' in sys.argv
    
    # Convert text to audio with debug flag
    convert_text_to_audio(input_file, output_file, voice=voice, stream=stream, 
                         speed=speed, lang=lang, split_output=split_output, 
                         format=format, debug=debug)

